{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee4ff94-640d-4ec1-91e5-ee2124c5eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_label_set = ['O','Disease', 'SportsManager', 'Software', 'WrittenWork', 'Food', 'Scientist', 'OtherLOC', 'Cleric', 'Medication/Vaccine', 'PublicCorp', 'VisualWork', 'OtherPER', 'Artist', 'Symptom', 'SportsGRP', 'MedicalProcedure', 'Athlete', 'PrivateCorp', 'ORG', 'Politician', 'ArtWork', 'Drink', 'Vehicle', 'MusicalGRP', 'AnatomicalStructure', 'HumanSettlement', 'CarManufacturer', 'Facility', 'AerospaceManufacturer', 'OtherPROD', 'Clothing', 'MusicalWork', 'Station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ccf775-b38f-49bb-afc5-6752397809d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba59666a-2657-4fb5-90c3-79591cb188c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import XLMRobertaTokenizerFast, XLMRobertaModel\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b61cd17-948c-4505-b57c-52d12be1dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the MultiCoNER dataset (English)\n",
    "dataset = load_dataset('MultiCoNER/multiconer_v2', 'English (EN)')\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# Select 100 random samples for low-resource setting\n",
    "train_indices = random.sample(range(len(train_dataset)), 100)\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "\n",
    "# Use the fast tokenizer\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-large')\n",
    "encoder = XLMRobertaModel.from_pretrained('xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4520b8-eed2-441a-8a99-e3620beeaf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label sets\n",
    "span_label_set = ['B', 'I', 'O']\n",
    "# entity_label_set = ['Person', 'Location', 'Corporation', 'Groups', 'Product', 'CreativeWork', 'O']\n",
    "span2id = {label: idx for idx, label in enumerate(span_label_set)}\n",
    "entity2id = {label: idx for idx, label in enumerate(entity_label_set)}\n",
    "\n",
    "def split_ner_tags(ner_tags):\n",
    "    span_labels = []\n",
    "    entity_labels = []\n",
    "    for tag in ner_tags:\n",
    "        if tag == \"O\":\n",
    "            span_labels.append(\"O\")\n",
    "            entity_labels.append(\"O\")\n",
    "        else:\n",
    "            bio, entity = tag.split(\"-\", 1)\n",
    "            span_labels.append(bio)\n",
    "            entity_labels.append(entity)\n",
    "    return span_labels, entity_labels\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_tokens = [item['tokens'] for item in batch]\n",
    "    batch_ner_tags = [item['ner_tags'] for item in batch]\n",
    "\n",
    "    batch_span_labels = []\n",
    "    batch_entity_labels = []\n",
    "    for ner_tags in batch_ner_tags:\n",
    "        span_labels, entity_labels = split_ner_tags(ner_tags)\n",
    "        batch_span_labels.append([span2id[label] for label in span_labels])\n",
    "        batch_entity_labels.append([entity2id[label] for label in entity_labels])\n",
    "\n",
    "    encodings = tokenizer(batch_tokens, is_split_into_words=True, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    input_ids = encodings['input_ids']\n",
    "    attention_mask = encodings['attention_mask']\n",
    "\n",
    "    max_len = input_ids.size(1)\n",
    "    padded_span_labels = []\n",
    "    padded_entity_labels = []\n",
    "    for idx, (span_labels, entity_labels) in enumerate(zip(batch_span_labels, batch_entity_labels)):\n",
    "        word_ids = encodings.word_ids(batch_index=idx)\n",
    "        aligned_span = []\n",
    "        aligned_entity = []\n",
    "        prev_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                aligned_span.append(-100)\n",
    "                aligned_entity.append(-100)\n",
    "            elif word_id != prev_word_id:\n",
    "                aligned_span.append(span_labels[word_id])\n",
    "                aligned_entity.append(entity_labels[word_id])\n",
    "            else:\n",
    "                aligned_span.append(-100)\n",
    "                aligned_entity.append(-100)\n",
    "            prev_word_id = word_id\n",
    "        padded_span_labels.append(aligned_span)\n",
    "        padded_entity_labels.append(aligned_entity)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'span_labels': torch.tensor(padded_span_labels),\n",
    "        'entity_labels': torch.tensor(padded_entity_labels)\n",
    "    }\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190174fc-c406-4b79-8faf-89f4ba2985aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class E2DAEndogenous(nn.Module):\n",
    "    def __init__(self, hidden_dim=1024, num_span_labels=len(span_label_set), num_entity_labels=len(entity_label_set)):\n",
    "        super(E2DAEndogenous, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.shared_extractor = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.span_extractor = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.type_extractor = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.span_head = nn.Linear(hidden_dim, num_span_labels)\n",
    "        self.type_head = nn.Linear(hidden_dim, num_entity_labels)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids, attention_mask=attention_mask)\n",
    "        H = outputs.last_hidden_state\n",
    "\n",
    "        H_share = self.shared_extractor(H)\n",
    "        H_st = H - H_share\n",
    "        H_span = self.span_extractor(H_st)\n",
    "        H_type = self.type_extractor(H_st)\n",
    "        H_sp = H_span + H_share\n",
    "        H_tp = H_type + H_share\n",
    "\n",
    "        span_logits = self.span_head(self.dropout(H_sp))\n",
    "        type_logits = self.type_head(self.dropout(H_tp))\n",
    "        return span_logits, type_logits, H_span, H_type, H_share\n",
    "\n",
    "# Endogenous Augmentation Loss\n",
    "def compute_covariance_matrix(features, labels, num_classes):\n",
    "    batch_size, seq_len, dim = features.size()\n",
    "    device = features.device  # Get the device of the input features\n",
    "    features_flat = features.view(-1, dim)\n",
    "    labels_flat = labels.view(-1)\n",
    "    cov_matrices = []\n",
    "    for c in range(num_classes):\n",
    "        class_features = features_flat[labels_flat == c]\n",
    "        if class_features.numel() > 0 and class_features.size(0) > 1:\n",
    "            cov = torch.cov(class_features.T)\n",
    "            cov_matrices.append(cov + torch.eye(dim, device=device) * 1e-6)\n",
    "        else:\n",
    "            cov_matrices.append(torch.eye(dim, device=device) * 1e-6)\n",
    "    return torch.stack(cov_matrices)\n",
    "\n",
    "def endogenous_loss(logits, labels, features, head_weights, head_bias, lambda_):\n",
    "    batch_size, seq_len, num_classes = logits.size()\n",
    "    cov_matrices = compute_covariance_matrix(features, labels, num_classes)\n",
    "\n",
    "    loss = 0\n",
    "    valid_tokens = 0\n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            if labels[i, j] != -100:\n",
    "                c_i = labels[i, j]\n",
    "                h_i = features[i, j]\n",
    "                log_sum_exp = 0\n",
    "                for c_j in range(num_classes):\n",
    "                    if c_j != c_i:\n",
    "                        delta_w = head_weights[c_j] - head_weights[c_i]\n",
    "                        delta_b = head_bias[c_j] - head_bias[c_i]\n",
    "                        mean_term = delta_w @ h_i + delta_b\n",
    "                        var_term = (lambda_ / 2) * delta_w @ cov_matrices[c_i] @ delta_w\n",
    "                        log_sum_exp += torch.exp(mean_term + var_term)\n",
    "                loss += torch.log(1 + log_sum_exp)\n",
    "                valid_tokens += 1\n",
    "    return loss / valid_tokens if valid_tokens > 0 else torch.tensor(0.0, device=logits.device)\n",
    "\n",
    "# Orthogonality Loss\n",
    "def orthogonality_loss(H_span, H_type, H_share):\n",
    "    dot1 = (H_span * H_share).sum(dim=-1).pow(2).mean()\n",
    "    dot2 = (H_type * H_share).sum(dim=-1).pow(2).mean()\n",
    "    dot3 = (H_span * H_type).sum(dim=-1).pow(2).mean()\n",
    "    return dot1 + dot2 + dot3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ae554c-0d0d-47c3-b013-42d243eaf2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E2DAEndogenous(\n",
       "  (encoder): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): XLMRobertaPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (shared_extractor): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (span_extractor): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (type_extractor): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (span_head): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  (type_head): Linear(in_features=1024, out_features=34, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = E2DAEndogenous().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "model.load_state_dict(torch.load(\"best_e2da_endogenous.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7125bdc-205a-4170-9090-f3e3ba98373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/435, Training Loss: 0.5209\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/435, Training Loss: 0.2763\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/435, Training Loss: 0.2199\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/435, Training Loss: 0.2147\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/435, Training Loss: 0.2067\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/435, Training Loss: 0.1912\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/435, Training Loss: 0.1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/435, Training Loss: 0.1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/435, Training Loss: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/435, Training Loss: 0.1931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/435, Training Loss: 0.1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/435, Training Loss: 0.1907\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/435, Training Loss: 0.1807\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/435, Training Loss: 0.1804\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/435, Training Loss: 0.1763\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/435, Training Loss: 0.1642\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/435, Training Loss: 0.1639\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/435, Training Loss: 0.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/435, Training Loss: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/435, Training Loss: 0.1721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/435, Training Loss: 0.1622\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/435, Training Loss: 0.1585\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/435, Training Loss: 0.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/435, Training Loss: 0.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/435, Training Loss: 0.1552\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/435, Training Loss: 0.1535\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/435, Training Loss: 0.1487\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/435, Training Loss: 0.1507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/435, Training Loss: 0.1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/435, Training Loss: 0.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/435, Training Loss: 0.1476\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/435, Training Loss: 0.1428\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/435, Training Loss: 0.1435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/435, Training Loss: 0.1411\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/435, Training Loss: 0.1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/435, Training Loss: 0.1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/435, Training Loss: 0.1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/435, Training Loss: 0.1357\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/435, Training Loss: 0.1343\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/435, Training Loss: 0.1373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/435, Training Loss: 0.1305\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/435, Training Loss: 0.1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/435, Training Loss: 0.1459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/435, Training Loss: 0.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/435, Training Loss: 0.1300\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/435, Training Loss: 0.1220\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/435, Training Loss: 0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/435, Training Loss: 0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/435, Training Loss: 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/435, Training Loss: 0.1186\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/435, Training Loss: 0.1143\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/435, Training Loss: 0.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/435, Training Loss: 0.1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/435, Training Loss: 0.1572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/435, Training Loss: 0.1423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/435, Training Loss: 0.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/435, Training Loss: 0.1128\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/435, Training Loss: 0.1087\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/435, Training Loss: 0.1084\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/435, Training Loss: 0.1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/435, Training Loss: 0.1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/435, Training Loss: 0.1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/435, Training Loss: 0.1036\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/435, Training Loss: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/435, Training Loss: 0.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/435, Training Loss: 0.1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/435, Training Loss: 0.1018\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/435, Training Loss: 0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/435, Training Loss: 0.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/435, Training Loss: 0.1084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/435, Training Loss: 0.1032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/435, Training Loss: 0.1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/435, Training Loss: 0.1002\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/435, Training Loss: 0.0945\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/435, Training Loss: 0.1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/435, Training Loss: 0.1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/435, Training Loss: 0.1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/435, Training Loss: 0.1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/435, Training Loss: 0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/435, Training Loss: 0.0988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/435, Training Loss: 0.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/435, Training Loss: 0.1020\n",
      "Early stopping triggered. Stopping training.\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "alpha = 0.01\n",
    "max_epochs = 435\n",
    "patience = 8  # Stop training if no improvement for 'patience' epochs\n",
    "best_train_loss = np.inf  # Track the best training loss\n",
    "epochs_no_improve = 0  # Count epochs with no improvement\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{max_epochs}\", leave=False)\n",
    "    \n",
    "    for batch in train_loader_tqdm:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        span_labels = batch['span_labels'].to(device)\n",
    "        entity_labels = batch['entity_labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        span_logits, type_logits, H_span, H_type, H_share = model(input_ids, attention_mask)\n",
    "\n",
    "        # Get classification head parameters\n",
    "        span_weights = model.span_head.weight.detach()\n",
    "        span_bias = model.span_head.bias.detach()\n",
    "        type_weights = model.type_head.weight.detach()\n",
    "        type_bias = model.type_head.bias.detach()\n",
    "\n",
    "        # Dynamic lambda\n",
    "        lambda_ = 1.5 * (epoch + 1) / max_epochs\n",
    "        span_loss = endogenous_loss(span_logits, span_labels, H_span, span_weights, span_bias, lambda_)\n",
    "        type_loss = endogenous_loss(type_logits, entity_labels, H_type, type_weights, type_bias, lambda_)\n",
    "        ortho_loss = orthogonality_loss(H_span, H_type, H_share)\n",
    "\n",
    "        loss = span_loss + type_loss + alpha * ortho_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Early Stopping Check (Based on Training Loss)\n",
    "    if avg_train_loss < best_train_loss:\n",
    "        best_train_loss = avg_train_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best_e2da_endogenous.pth\")  # Save best model\n",
    "        print(\"Model saved!\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        # print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72faf4-e417-428b-9832-e0946ed2c511",
   "metadata": {},
   "source": [
    "150 epochs already runned, model was loaded again for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f59760-dafa-47bb-a790-8e3998c28bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.save(model.state_dict(), \"e2da_endogenous2.pth\")\n",
    "print(\"Model saved successfully.\")\n",
    "# model.load_state_dict(torch.load(\"e2da_endogenous.pth\"))\n",
    "# model.to(device)\n",
    "# model.eval()  # Set the model to evaluation mode if using for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50da3535-fa57-4ce1-8737-fbd47dfb70fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Micro-F1 (non-'O'): 0.5113\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Test Evaluation with tqdm\n",
    "model.eval()\n",
    "test_preds, test_labels = [],[]\n",
    "\n",
    "test_loader_tqdm = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_tqdm:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        span_labels = batch['span_labels'].to(device)\n",
    "        entity_labels = batch['entity_labels'].to(device)\n",
    "\n",
    "        span_logits, type_logits, _, _, _ = model(input_ids, attention_mask)\n",
    "        span_preds = torch.argmax(span_logits, dim=-1)\n",
    "        type_preds = torch.argmax(type_logits, dim=-1)\n",
    "\n",
    "        for i in range(span_preds.size(0)):\n",
    "            for j in range(span_preds.size(1)):\n",
    "                if span_labels[i, j] != -100:  # Ignore padding tokens\n",
    "                    # Construct the predicted and true labels\n",
    "                    pred_label = f\"{span_label_set[span_preds[i, j]]}-{entity_label_set[type_preds[i, j]]}\" if span_preds[i, j] != 2 else \"O\"\n",
    "                    true_label = f\"{span_label_set[span_labels[i, j]]}-{entity_label_set[entity_labels[i, j]]}\" if span_labels[i, j] != 2 else \"O\"\n",
    "\n",
    "                    # Only append non-\"O\" labels to the lists\n",
    "                    if pred_label != \"O\" and true_label != \"O\":\n",
    "                        test_preds.append(pred_label)\n",
    "                        test_labels.append(true_label)\n",
    "\n",
    "# Compute Micro-F1 Score for non-\"O\" predictions\n",
    "micro_f1 = f1_score(test_labels, test_preds, average='micro')\n",
    "print(f\"Test Micro-F1 (non-'O'): {micro_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651dc86-24be-40a4-98fa-ffa71a1d984a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
